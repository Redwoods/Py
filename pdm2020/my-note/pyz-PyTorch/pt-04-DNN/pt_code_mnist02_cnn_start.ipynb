{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch MNIST\n",
    "- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:00, 10478729.67it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 29726503.96it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▊      | 636928/1648877 [00:00<00:00, 6306406.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 3674109.01it/s]                             \n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\life21c\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "# 총 배치의 수를 출력해보겠습니다.\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start :\n",
      "[Epoch:    1] cost = 0.225688592\n",
      "[Epoch:    2] cost = 0.0630272627\n",
      "[Epoch:    3] cost = 0.0462014414\n",
      "[Epoch:    4] cost = 0.0372817144\n",
      "[Epoch:    5] cost = 0.0312065613\n",
      "[Epoch:    6] cost = 0.0257067289\n",
      "[Epoch:    7] cost = 0.0212643575\n",
      "[Epoch:    8] cost = 0.0179218333\n",
      "[Epoch:    9] cost = 0.0158441812\n",
      "[Epoch:   10] cost = 0.0131147271\n",
      "[Epoch:   11] cost = 0.00988591649\n",
      "[Epoch:   12] cost = 0.0094961524\n",
      "[Epoch:   13] cost = 0.00843453128\n",
      "[Epoch:   14] cost = 0.00656150794\n",
      "[Epoch:   15] cost = 0.00671146298\n",
      "Learning finished\n",
      "Training Executed in 86.3286413 sec\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "print(\"Training start :\")\n",
    "# Training\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "print('Learning finished')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Training Executed in \" + str(execution_time) + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9863999485969543\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9863999485969543\n",
      "Label:  5\n",
      "Prediction:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1,1, 28, 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('tf2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
