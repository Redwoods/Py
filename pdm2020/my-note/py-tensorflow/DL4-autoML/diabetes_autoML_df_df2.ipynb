{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "diabetes_autoML_df_df2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "edL3BuYVz-x7"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3834ce636a3ba6c6c2bd8b9b527c48eede78c367f849f6cce666ea7f1d26e2fb"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redwoods/Py/blob/master/pdm2020/my-note/py-tensorflow/DL4-autoML/diabetes_autoML_df_df2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6gwVt9qxlxi"
      },
      "source": [
        "# Diabetes\n",
        "- [dataset from kaggle](https://www.kaggle.com/himanshu86503/dibetes33hi)\n",
        "## AutoML\n",
        "- raw data\n",
        "- imputed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZIe0Vjhz-xt"
      },
      "source": [
        "## 1. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2AR6z3Pz-xw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhj3--X0z-xy"
      },
      "source": [
        "## 2. Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBx--oGBz-xz"
      },
      "source": [
        "# Get the data from github\n",
        "url = \"https://github.com/Redwoods/Py/raw/master/pdm2020/my-note/py-pandas/data/diabetes.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a8gpSiGz-x0"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVRz854vz-x1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwGTzCuWthQZ"
      },
      "source": [
        "#  int or float ?\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPITBmUz-x1"
      },
      "source": [
        "### Cleaning data\n",
        "- Check the NaN or missing values\n",
        "- Clean the null data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Ks4T4Pz-x2"
      },
      "source": [
        "# Importing the dataset\n",
        "# data = pd.read_csv('diabetes.csv')\n",
        "#CHECK FOR NULL VALUES\n",
        "df.isnull().values.any(), df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF0S1H9kz-x3"
      },
      "source": [
        "# Drop unused columns, and drop rows with any missing values. (NOT neceaasry always!)\n",
        "print(df.shape)\n",
        "vars = df.columns\n",
        "print(vars)\n",
        "df = df[vars].dropna()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJMZi8-Uz-x5"
      },
      "source": [
        "## 3. Explore Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MpjASeothQb"
      },
      "source": [
        "### 위의 데이터에서 문제점을 찾으시오.\n",
        "- 0이 허용되지 않는 특징이 있는가?\n",
        "- 값 0을 어떤 값으로 변경해야하는가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooMesUSAthQc"
      },
      "source": [
        "# Check zeros in features without Outcome\n",
        "(df.iloc[:,:8]==0).astype(int).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkOqiz06z-x6"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx3auWToz-x6"
      },
      "source": [
        "### Check the balance of the data through plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUBL5viiz-x7"
      },
      "source": [
        "# Check the balance of the data through plot\n",
        "classes=df.Outcome\n",
        "ax=sns.countplot(classes, label='count')\n",
        "plt.show()\n",
        "nDB,DB=classes.value_counts()\n",
        "print('False: non-diabetes',nDB)\n",
        "print('True: diabetes',DB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvR6KydGz-x7"
      },
      "source": [
        "classes.value_counts(), type(classes) # noDM: 500, DM: 268"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFv5mpZ8z-x7"
      },
      "source": [
        "## correlation plot (상관도표)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YemDAjKoz-x7"
      },
      "source": [
        "#correlation plot\n",
        "cormat=df.corr()\n",
        "plt.figure(figsize=(12,10))\n",
        "g=sns.heatmap(cormat, annot=True, cmap='coolwarm', #cmap= \"RdYlGn\",\n",
        "             vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edL3BuYVz-x7"
      },
      "source": [
        "### 상관성 분석 결과\n",
        "* Age vs. Pregnancies : 0.54\n",
        "* Glucose vs. Outcome : 0.47\n",
        "* SkinThickness vs. Insulin : 0.44\n",
        "* SkinThickness vs. BMI : 0.39\n",
        "\n",
        "> 좀 더 자세한 시각화가 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFhwDpKnthQe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOzlJGjthQe"
      },
      "source": [
        "## 각 특징의 내부 정보를 고려한 zero 처리 후 상관성 조사."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRqM20uEthQe"
      },
      "source": [
        "# zero 처리 함수\n",
        "# Clean the data : zero2median()\n",
        "# 1. Check zeros in features with Pregnancies, Outcome excluded.\n",
        "# 2. Replace zero with NaN \n",
        "# 3. Replace NaN with the median of the corresponding featurs\n",
        "def zero2median(df):\n",
        "    columns_with_zero = df.columns[(df==0).sum() > 0][1:-1]\n",
        "    # Index(['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI'], dtype='object')\n",
        "    df[columns_with_zero]=df[columns_with_zero].replace(0,np.nan)\n",
        "    for feature in columns_with_zero:\n",
        "        df[feature].fillna(df[feature].median(),inplace=True)  # median() -> mean()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Srart with cleaned dataframe\n",
        "df2 = zero2median(df)\n",
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGcs6V_bthQf"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeAUP3lUthQf"
      },
      "source": [
        "#correlation plot of df2\n",
        "# cormat2=df2.corr()\n",
        "plt.figure(figsize=(12,10))\n",
        "g3=sns.heatmap(df2.corr(),annot=True,cmap='coolwarm', #cmap= \"RdYlGn\",\n",
        "             vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05tVHOcithQf"
      },
      "source": [
        "## 데이터프레임 df, df2의 상관성이 달라짐을 확인하시오.\n",
        "### 상관성 분석 결과 \n",
        "* Age vs. Pregnancies : 0.54 ->  0.54\n",
        "* Glucose vs. Outcome : 0.47 ->  0.49\n",
        "* SkinThickness vs. Insulin : 0.44 -> 0.16\n",
        "* SkinThickness vs. BMI : 0.39 -> 0.54\n",
        "\n",
        "> 상관성 최종 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPkMC0imG9wi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt_Oj3bnthQg"
      },
      "source": [
        "### 그러면 다음 autoML에서는 어떤 데이터로 ML 모델을 만들어야하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW2f5pgr3IQI"
      },
      "source": [
        "# AutoML\n",
        "- ## pycaret\n",
        "- ## data : df, df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K61abq78lIK3"
      },
      "source": [
        "# targets\n",
        "- ## 'noDM', 'DM'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTc9q7DO3xXI"
      },
      "source": [
        "# !pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlVMp_UXwOXX"
      },
      "source": [
        "# check version\n",
        "from pycaret.utils import version\n",
        "version()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWhvmnEAhMJa"
      },
      "source": [
        "from pycaret.classification import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD290GGwthQg"
      },
      "source": [
        "## autoML using df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulcFCvV1thQg"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyiBSlUtthQh"
      },
      "source": [
        "### Make data for pycaret autoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bVE8DRJnw3I"
      },
      "source": [
        "data = df.sample(frac=0.8, random_state=786)  # 8:2 split\n",
        "data_unseen = df.drop(data.index).reset_index(drop=True)  # test data : 20%\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Data for Modeling: ' + str(data.shape))\n",
        "print('Unseen Data For Predictions ' + str(data_unseen.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLBLikI1nw3J"
      },
      "source": [
        "clf = setup(data = data, target = 'Outcome', session_id=1104, \n",
        "                    normalize=True, \n",
        "                    transformation=True, \n",
        "                    ignore_low_variance=True,\n",
        "        #    remove_multicollinearity=True, multicollinearity_threshold=0.95,\n",
        "                    silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLkthiNnw3K"
      },
      "source": [
        "best_model = compare_models(sort='Accuracy')\n",
        "# compare_models(sort='AUC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VWyc_94thQh"
      },
      "source": [
        "## Meaning of Prec., Recall,  F1, AUC\n",
        "- Precision (Pres.) is an indication of how many positive\n",
        "predictions are correct\n",
        "- Recall identifies how many actual positive examples are correctly identified. \n",
        "> There is always a tradeoff between precision and recall so a new performance measuring parameter F1 score is introduced. \n",
        "- F1 score is a harmonic mean of precision and recall which gives a balance value between precision and recall.\n",
        "- AUC is a measure of the area under the receiver operating characteristic curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVtMz_Afgm2"
      },
      "source": [
        "current_model = 'rf'  # lightgbm\n",
        "model = create_model(current_model, fold =10)\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa0S4-FcUvHk"
      },
      "source": [
        "plot_model(model, plot = 'confusion_matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urfeL5RG_fbN"
      },
      "source": [
        "plot_model(model, plot = 'feature')\n",
        "print(model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59QVvJWbHd09"
      },
      "source": [
        "## SHAP\n",
        "- https://eair.tistory.com/30?category=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-LZ9kj5PfGF"
      },
      "source": [
        "# !pip install shap\n",
        "interpret_model(model)  # Interpretability of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS6LEHAIthQi"
      },
      "source": [
        "# Best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMEphVN9-3Sk"
      },
      "source": [
        "plot_model(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qQ4EKq7-3Sr"
      },
      "source": [
        "# LABELS = ['noDM', 'DM']\n",
        "plot_model(best_model, plot = 'confusion_matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVb4-6Rf-3Sr"
      },
      "source": [
        "plot_model(best_model, plot = 'feature')\n",
        "# print(best_model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pcytzav-3Sr"
      },
      "source": [
        "## SHAP - xAI\n",
        "- https://eair.tistory.com/30?category=0\n",
        "- tree를 이용한 ML 모델에 적용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPvacETq-3Ss"
      },
      "source": [
        "# interpret_model(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wtFgnDEthQj"
      },
      "source": [
        "## Pycaret - score\n",
        "- 테스트 데이터에 적용하여 성능 평가.\n",
        "- https://towardsdatascience.com/predict-lead-score-the-right-way-using-pycaret-332faa780cfc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OACPVf_thQj"
      },
      "source": [
        "type(data_unseen),data_unseen.shape,data_unseen.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ZOaaVfkuyR"
      },
      "source": [
        "# Predict test data\n",
        "unseen_best_predictions = predict_model(best_model, data=data_unseen)\n",
        "unseen_best_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGR9HbIzthQj"
      },
      "source": [
        "# unseen_predictions\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = list(unseen_best_predictions['Label'].values)\n",
        "y_true = list(unseen_best_predictions['Outcome'].values)\n",
        "best_accuracy = accuracy_score(y_true, y_pred)\n",
        "print(\"Accuracy of the best model: {}\".format(best_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQFsAlbrthQj"
      },
      "source": [
        "### 트레이닝 accuracy 76.6% -> **No overfitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNpp-Q0tz-yA"
      },
      "source": [
        "#confusion matrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nkFJ4--thQk"
      },
      "source": [
        "## Summary of the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVC7nJ7qthQk"
      },
      "source": [
        "evaluate_model(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5MevWlqthQk"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FNfKFEkthQk"
      },
      "source": [
        "## autoML using df2\n",
        "- df2 : zero-preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q22SPJlGthQk"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M2Wn3FbthQk"
      },
      "source": [
        "### 위에서 Pregnancies, Age가 categorical(정수) feature. -> 해결 방법은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GA4hrIthQk"
      },
      "source": [
        "# pycaret으로 학습할려면 특징값은 float\n",
        "df2['Pregnancies'] = df['Pregnancies'].astype(float)\n",
        "df2['Age'] = df['Age'].astype(float)\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g0Oy2ERthQl"
      },
      "source": [
        "data = df2.sample(frac=0.8, random_state=786)  # 8:2 split\n",
        "data_unseen = df2.drop(data.index).reset_index(drop=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Using df2')\n",
        "print('Data for Modeling: ' + str(data.shape))\n",
        "print('Unseen Data For Predictions ' + str(data_unseen.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq3fsRyIthQl"
      },
      "source": [
        "clf = setup(data = data, target = 'Outcome', session_id=1104, \n",
        "                    normalize=True, \n",
        "                    transformation=True, \n",
        "                    ignore_low_variance=True,\n",
        "        #    remove_multicollinearity=True, multicollinearity_threshold=0.95,\n",
        "                    silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWnUDVoEthQl"
      },
      "source": [
        "best_model2 = compare_models(sort='Accuracy')\n",
        "# compare_models(sort='AUC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaM5xZoxthQl"
      },
      "source": [
        "### Accuracy가 약간 높아졌지만 큰 차이는 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10zPcdqFthQl"
      },
      "source": [
        "plot_model(best_model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axdflIl7thQl"
      },
      "source": [
        "plot_model(best_model2, 'confusion_matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRnnB5gJthQl"
      },
      "source": [
        "plot_model(best_model2, plot = 'feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF8JfHO4thQm"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI88bU7ROgq8"
      },
      "source": [
        "## [도전하기 - DIY]\n",
        "- 최적의 모델을 찾아서 저장\n",
        "    - save_model()\n",
        "- 저장된 모델을 불러와서 테스트 데이터에 적용\n",
        "    - load_model()\n",
        "- 모델별로 accuracy를 표로 정리하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zospj_4NthQm"
      },
      "source": [
        "---\n",
        "---"
      ]
    }
  ]
}